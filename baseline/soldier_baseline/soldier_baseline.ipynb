{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from zhipuai import ZhipuAI\n",
    "Access_Token = 'Your Team Account'  # 比赛队伍Token，用于访问比赛数据库\n",
    "MODEL_sql = \"glm-4-plus\"  #\"glm-4-plus\"#\"glm-4-flashx\"\n",
    "MODEL_rag = \"glm-4-plus\"  #\"glm-4-plus\"#\"glm-4-flashx\"\n",
    "client = ZhipuAI(api_key='Your ZhipuAI API_KEY')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 工具函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 LLM生成数据"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import queue\n",
    "\n",
    "\n",
    "def create_chat_completion(messages, model):\n",
    "    \"\"\"\n",
    "    Create a chat completion using the provided messages and model.\n",
    "    \n",
    "    Parameters:\n",
    "        messages (list): A list of message dictionaries to pass to the model.\n",
    "        model (str): The model name to use.\n",
    "    \n",
    "    Returns:\n",
    "        response (dict): The response from the chat completion endpoint.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        stream=False,\n",
    "        messages=messages,\n",
    "        temperature= 0.5\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def _threaded(func):\n",
    "    \"\"\"\n",
    "    A function that adds threading capabilities to a function.\n",
    "    The returned function will take two additional arguments: thread_id and result_queue.\n",
    "    It will run the function and put the result in the result_queue as a tuple (thread_id, result).\n",
    "\n",
    "    Args:\n",
    "        func (Callable): The function to be wrapped.\n",
    "\n",
    "    Returns:\n",
    "        Callable: The wrapped function.\n",
    "    \"\"\"\n",
    "    def wrapper(*args, thread_id, result_queue, **kwargs):\n",
    "        try:\n",
    "            result = func(*args, **kwargs)\n",
    "            result_queue.put((thread_id, result))\n",
    "        except Exception as e:\n",
    "            print(f\"Exception in thread with kwargs: {kwargs}\\n{e}\")\n",
    "            result_queue.put((thread_id, None))\n",
    "    return wrapper\n",
    "\n",
    "def async_llm_chain_call(\n",
    "    messages,\n",
    "    model,\n",
    "    sampling_count = 1,\n",
    ") :\n",
    "\n",
    "    call_list = []\n",
    "    engine_id = 0\n",
    "    for _ in range(sampling_count):\n",
    "        call_list.append({\n",
    "            'function': create_chat_completion,\n",
    "            'kwargs': {\n",
    "                'messages': messages,    \n",
    "                'model': model,    \n",
    "                }\n",
    "        })\n",
    "        engine_id += 1\n",
    "\n",
    "    result_queue = queue.Queue()\n",
    "    # with ThreadPoolExecutor(max_workers=len(call_list)) as executor:\n",
    "    with ThreadPoolExecutor(max_workers=20) as executor:\n",
    "        for idx, call in enumerate(call_list):\n",
    "            func = _threaded(call['function'])\n",
    "            kwargs = call['kwargs']\n",
    "            executor.submit(func, thread_id=idx, result_queue=result_queue, **kwargs)\n",
    "\n",
    "    results = []\n",
    "    while not result_queue.empty():\n",
    "        results.append(result_queue.get())\n",
    "\n",
    "    # Sort results based on their thread IDs\n",
    "    results = sorted(results, key=lambda x: x[0])\n",
    "    sorted_results = [result[1] for result in results]\n",
    "    if len(sorted_results) == 1:\n",
    "        return sorted_results[0]\n",
    "\n",
    "    _sorted_results = {}\n",
    "    for i, result in results:\n",
    "        # select_result, intro_str = to_select(result.choices[0].message.content)\n",
    "        try:\n",
    "            _sorted_results[i] = [result.choices[0].message.content]\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    idx_ = get_best(_sorted_results, messages, model)\n",
    "\n",
    "    return sorted_results[idx_]\n",
    "\n",
    "def get_best(sorted_results, context, model):\n",
    "    prompt = f\"\"\"Instructions:\n",
    "--------------\n",
    "根据对话上下文，请从下面的回复中选择一个最好的回复，只输出回复的标号\n",
    "--------------\n",
    "这是上下文：{str(context)}\n",
    "---------------\n",
    "这是回复：\n",
    "--------------\n",
    "{str(sorted_results)}\n",
    "--------------\n",
    "\n",
    "请仅回复标号：\"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = create_chat_completion(messages, model)\n",
    "    answer = response.choices[0].message.content\n",
    "    num = len(sorted_results)\n",
    "    for i in range(num):\n",
    "        if str(i) in answer:\n",
    "            return i\n",
    "    return 0"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 找到LLM回复中的json数据"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def find_json(text):\n",
    "    \"\"\"\n",
    "    Attempt to extract and parse a JSON object from the provided text.\n",
    "    The function tries up to three attempts using two patterns:\n",
    "      1. A Markdown code block with ```json ... ```\n",
    "      2. A more general JSON-like pattern using { and }\n",
    "\n",
    "    If successful, returns the parsed JSON data.\n",
    "    If parsing fails after all attempts, returns the original text.\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): The input text from which to extract JSON.\n",
    "    \n",
    "    Returns:\n",
    "        dict or str: Parsed JSON dictionary if successful, else the original text.\n",
    "    \"\"\"\n",
    "    max_attempts = 3\n",
    "    for attempt in range(1, max_attempts + 1):\n",
    "        json_pattern = r\"```json\\n(.*?)\\n```\"\n",
    "        match = re.search(json_pattern, text, re.DOTALL)\n",
    "        if not match:\n",
    "            json_pattern2 = r\"({.*?})\"\n",
    "            match = re.search(json_pattern2, text, re.DOTALL)\n",
    "\n",
    "        if match:\n",
    "            json_string = match.group(1) if match.lastindex == 1 else match.group(0)\n",
    "            # Remove Markdown formatting if present\n",
    "            json_string = json_string.replace(\"```json\\n\", \"\").replace(\"\\n```\", \"\")\n",
    "            try:\n",
    "                data = json.loads(json_string)\n",
    "                return data\n",
    "            except json.JSONDecodeError as e:\n",
    "                if attempt < max_attempts:\n",
    "                    text = fix_json(json_string, e, model=MODEL_rag)\n",
    "                    print(f\"Attempt {attempt}: Failed to parse JSON, reason: {e}. Retrying...\")\n",
    "                    # 写入log文件\n",
    "                    with open(\"log.txt\", \"a\") as f:\n",
    "                        f.write(f\"Attempt {attempt}: Failed to parse JSON, reason: {e}. Retrying...\\n\")\n",
    "                else:\n",
    "                    print(f\"All {max_attempts} attempts to parse JSON failed. Returning original text.\")\n",
    "                    # 写入log文件\n",
    "                    with open(\"log.txt\", \"a\") as f:\n",
    "                        f.write(f\"All {max_attempts} attempts to parse JSON failed. Returning original text.\\n\")\n",
    "        else:\n",
    "            if attempt < max_attempts:\n",
    "                print(f\"Attempt {attempt}: No JSON string found in the text. Retrying...\")\n",
    "                # 写入log文件\n",
    "                with open(\"log.txt\", \"a\") as f:\n",
    "                    f.write(f\"Attempt {attempt}: No JSON string found in the text. Retrying...\\n\")\n",
    "            else:\n",
    "                print(\"No matching JSON string found. Returning original text.\")\n",
    "                # 写入log文件\n",
    "                with open(\"log.txt\", \"a\") as f:\n",
    "                    f.write(\"No matching JSON string found. Returning original text.\\n\")\n",
    "\n",
    "        # If no match or no success in this attempt, return the original text\n",
    "    return text\n",
    "\n",
    "def fix_json(text, json_error, model):\n",
    "    \"\"\"\n",
    "    修复JSON字符串，使其成为有效的JSON。\n",
    "    \"\"\"\n",
    "    NAIVE_FIX = f\"\"\"Instructions:\n",
    "--------------\n",
    "请修复JSON字符串，使其成为有效的JSON。\n",
    "--------------\n",
    "\n",
    "下面是原始的JSON字符串：\n",
    "--------------\n",
    "{text}\n",
    "--------------\n",
    "下面是的错误信息：\n",
    "--------------\n",
    "{json_error}\n",
    "--------------\n",
    "\n",
    "请仅回复json，用```json ... ```包裹json字符串：\"\"\"\n",
    "    \n",
    "    messages = [{\"role\": \"user\", \"content\": NAIVE_FIX}]\n",
    "    response = create_chat_completion(messages, model)\n",
    "    answer = response.choices[0].message.content\n",
    "    return answer\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 读取题目文件相关函数"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import jieba\n",
    "\n",
    "def map_chinese_to_english_tables(chinese_names, english_names):\n",
    "    \"\"\"\n",
    "    Map Chinese table names to their corresponding English table names.\n",
    "    For each Chinese name, there is a matching English name \n",
    "    (case-insensitive comparison).\n",
    "    \n",
    "    Parameters:\n",
    "        chinese_names (list): A list of Chinese table names.\n",
    "        english_names (list): A list of English table names.\n",
    "        \n",
    "    Returns:\n",
    "        name_map (dict): A dictionary mapping Chinese table names to English table names.\n",
    "    \"\"\"\n",
    "    name_map = {}\n",
    "    for cname in chinese_names:\n",
    "        # Find the corresponding English name (case-insensitive match)\n",
    "        english_match = [en for en in english_names if str(en).lower() == cname.lower()][0]\n",
    "        name_map[cname] = english_match\n",
    "    return name_map\n",
    "\n",
    "def get_table_schema(table_shema, database_table_en, question=''):\n",
    "    \"\"\"\n",
    "    Retrieve table schemas along with optional filtered field comments.\n",
    "    If a question is provided, the comments will be filtered based on \n",
    "    question keywords.\n",
    "    \n",
    "    The function:\n",
    "      1. Maps Chinese table names to English table names.\n",
    "      2. For each table, retrieves its structure and finds associated comments.\n",
    "      3. If a question is provided, filter the comments based on keywords extracted from the question.\n",
    "    \n",
    "    Parameters:\n",
    "        question (str): The question text. If empty, no filtering is performed.\n",
    "        table_shema (list): A list of dictionaries containing table schema information.\n",
    "        \n",
    "    Returns:\n",
    "        table_maps (list): A list of dictionaries, each containing table schema information.\n",
    "        {\n",
    "            '数据表名': EnglishTableName,\n",
    "            '数据表结构': TableStructure,\n",
    "            '字段注释': FilteredComments (optional if question is provided)\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    parsed_tables = table_shema\n",
    "\n",
    "    # List of Chinese table names (keys)\n",
    "    chinese_table_names = [i['table'] for i in parsed_tables]\n",
    "\n",
    "    name_map = map_chinese_to_english_tables(chinese_table_names, database_table_en)\n",
    "\n",
    "\n",
    "    table_maps = []\n",
    "    for table in parsed_tables:\n",
    "        \n",
    "        # Filter comments based on question\n",
    "        table_map = {\n",
    "            '数据表名': name_map.get(table['table']),\n",
    "            '数据表结构': get_simple_schema(table['schema'], question),\n",
    "            # '字段注释': filtered_comments\n",
    "        }\n",
    "\n",
    "        table_maps.append(table_map)\n",
    "\n",
    "    return table_maps\n",
    "\n",
    "\n",
    "def get_simple_schema(table_schema, question):\n",
    "    table_simple = []\n",
    "    if question == \"\":\n",
    "        for table in table_schema:\n",
    "            data_example = table[\"数据示例\"]\n",
    "            # 数据示例取前50个字符\n",
    "            data_example = str(data_example)[:50]\n",
    "            table_simple.append({\n",
    "                \"列名\": table[\"列名\"],\n",
    "                '中文描述': table[\"中文描述\"],\n",
    "                '数据示例': data_example,\n",
    "            })\n",
    "    else:\n",
    "        for table in table_schema:\n",
    "            data_example = table[\"数据示例\"]\n",
    "            # 数据示例取前50个字符\n",
    "            data_example = str(data_example)[:50]\n",
    "            comment = is_add_comment(question, table[\"注释\"])\n",
    "            if comment:\n",
    "                table_simple.append({\n",
    "                    \"列名\": table[\"列名\"],\n",
    "                    '中文描述': table[\"中文描述\"],\n",
    "                    '数据示例': data_example,\n",
    "                    '注释': comment,\n",
    "                })\n",
    "            else:\n",
    "                table_simple.append({\n",
    "                    \"列名\": table[\"列名\"],\n",
    "                    '中文描述': table[\"中文描述\"],\n",
    "                    '数据示例': data_example,\n",
    "                })\n",
    "    \n",
    "    return table_simple\n",
    "\n",
    "def is_add_comment(question, comment):\n",
    "    if comment and str(comment) != \"nan\":\n",
    "        stopwords = ['？', '有', '的', '多少', '人', '（', '）']\n",
    "        seg_list = list(jieba.cut(question, cut_all=False))\n",
    "        filtered_seg_list = [word for word in seg_list if word not in stopwords]\n",
    "\n",
    "        if any(keyword in comment for keyword in filtered_seg_list):\n",
    "            return comment\n",
    "    return None\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Remove any parenthetical segments (including Chinese parentheses) and trim whitespace.\n",
    "    For example, \"This is a sentence(remark)\" -> \"This is a sentence\"\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): The text to clean.\n",
    "        \n",
    "    Returns:\n",
    "        str: The cleaned text.\n",
    "    \"\"\"\n",
    "    pattern = r'[\\(（][^\\)）]*[\\)）]'  # Pattern to match parentheses and their contents\n",
    "    cleaned_text = re.sub(pattern, '', text).strip()\n",
    "    return cleaned_text\n",
    "\n",
    "def find_dict_by_element(dict_list, target_element):\n",
    "    \"\"\"\n",
    "    Given a list of dictionaries, return all dictionaries where  '列名中文描述' contains the target_element.\n",
    "    Parameters:\n",
    "        dict_list (list): A list of dictionaries, each expected to have '列名中文描述' key.\n",
    "        target_element (str): The element to search for.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of dictionaries that contain target_element in '列名中文描述'.\n",
    "    \"\"\"\n",
    "    return [d for d in dict_list if target_element in d.get('列名中文描述', [])]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 其他"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def read_foreigns(foreigns_path):\n",
    "    # 读取外键信息,txt文件\n",
    "    with open(foreigns_path, 'r') as f:\n",
    "        foreigns = f.readlines()\n",
    "    foreigns = set([tuple(set(line.strip().split('='))) for line in foreigns])\n",
    "    foreigns = [f\"{foreign[0]}={foreign[1]}\" for foreign in foreigns if len(foreign) == 2]\n",
    "\n",
    "    return foreigns\n",
    "\n",
    "def dict_to_sentence(data):\n",
    "    \"\"\"\n",
    "    Convert a dictionary into a descriptive sentence by enumerating key-value pairs.\n",
    "    For example: {\"name\": \"John\", \"age\": 30} -> \"name 是 John, age 是 30\"\n",
    "    \n",
    "    Parameters:\n",
    "        data (dict): The dictionary to convert.\n",
    "        \n",
    "    Returns:\n",
    "        str: A sentence describing the dictionary keys and values.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not isinstance(data, dict):\n",
    "            raise ValueError(\"Input is not a dictionary\")\n",
    "\n",
    "        return \", \".join(f\"{key} 是 {value}\" for key, value in data.items())\n",
    "    except Exception as e:\n",
    "        print(f\"Error in dict_to_sentence: {e}\")\n",
    "        # 写入log文件\n",
    "        with open(\"log.txt\", \"a\") as f:\n",
    "            f.write(f\"Error in dict_to_sentence: {e}\\n\")\n",
    "        return str(data)\n",
    "\n",
    "def process_dict(d):\n",
    "    \"\"\"\n",
    "    Recursively process a nested dictionary to produce a comma-separated description.\n",
    "    For nested dictionaries, it processes them recursively and returns a descriptive string.\n",
    "    \n",
    "    For example:\n",
    "        {\n",
    "            \"company\": {\n",
    "                \"name\": \"ABC Corp\",\n",
    "                \"location\": \"New York\"\n",
    "            },\n",
    "            \"year\": 2021\n",
    "        }\n",
    "    might be processed into a string like:\n",
    "        \"company company 是 name 是 ABC Corp, location 是 New York, year 2021\"\n",
    "    \n",
    "    Parameters:\n",
    "        d (dict): A dictionary or another object to describe.\n",
    "        \n",
    "    Returns:\n",
    "        str: A descriptive string.\n",
    "    \"\"\"\n",
    "\n",
    "    def recursive_process(sub_dict):\n",
    "        sentences = []\n",
    "        for key, value in sub_dict.items():\n",
    "            if isinstance(value, dict):\n",
    "                # Process nested dictionary and wrap result in dict_to_sentence for formatting\n",
    "                nested_result = recursive_process(value)\n",
    "                sentences.append(dict_to_sentence({key: nested_result}))\n",
    "            else:\n",
    "                # Non-dict values are directly appended\n",
    "                sentences.append(f\"{key} {value}\")\n",
    "        return \", \".join(sentences)\n",
    "\n",
    "    if not isinstance(d, dict):\n",
    "        # If it's not a dictionary, just return its string representation\n",
    "        return str(d)\n",
    "\n",
    "    return recursive_process(d)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 预处理数据表结构\n",
    "## 2.1 改进题目提供的数据表结构"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def make_sql_schema(column_name, table_name):\n",
    "    sql_text = f\"\"\"\n",
    "    SELECT {column_name} FROM {table_name};\n",
    "    \"\"\"\n",
    "    return sql_text\n",
    "\n",
    "def select_data_schema(sql_text):\n",
    "    \"\"\"\n",
    "    Sends the given SQL query to a specified endpoint and returns the JSON response.\n",
    "    \n",
    "    Parameters:\n",
    "        sql_text (str): The SQL query to be executed.\n",
    "        \n",
    "    Returns:\n",
    "        str: The JSON response from the API, formatted with indentation.\n",
    "    \"\"\"\n",
    "    url = \"https://comm.chatglm.cn/finglm2/api/query\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f'Bearer {Access_Token}'\n",
    "    }\n",
    "    data = {\n",
    "        \"sql\": sql_text,  # e.g. SELECT * FROM constantdb.secumain LIMIT 10\n",
    "        \"limit\": 100\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=data)    \n",
    "    response_json = response.json()\n",
    "    if response.status_code == 200:\n",
    "        examples = response_json.get('data')\n",
    "        for example in examples:\n",
    "            # 得到字典example的values\n",
    "            value = list(example.values())[0]\n",
    "            if value:\n",
    "                return str(value)[:50]\n",
    "        return None\n",
    "    else:\n",
    "        # 抛出异常，并打印错误信息\n",
    "        print(response.status_code)\n",
    "        print(sql_text)\n",
    "        return None\n",
    "        # raise Exception(response.status_code)\n",
    "\n",
    "def get_value(col_name, table_name):\n",
    "    \"\"\"\n",
    "    判断字段col_name的值是否是唯一的\n",
    "    \"\"\"\n",
    "    sql_text = f\"SELECT DISTINCT {col_name} FROM {table_name} ;\"\n",
    "\n",
    "    url = \"https://comm.chatglm.cn/finglm2/api/query\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f'Bearer {Access_Token}'\n",
    "    }\n",
    "    data = {\n",
    "        \"sql\": sql_text,  # e.g. SELECT * FROM constantdb.secumain LIMIT 10\n",
    "        \"limit\": 100\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=data)    \n",
    "    response_json = response.json()\n",
    "    if response.status_code == 200:\n",
    "        examples = response_json.get('data')\n",
    "        if len(examples) == 1:\n",
    "            return False\n",
    "        return examples\n",
    "    else:\n",
    "        # 抛出异常，并打印错误信息\n",
    "        print(response.status_code)\n",
    "        print(sql_text)\n",
    "        return False\n",
    "\n",
    "# 读取官方的数据表信息\n",
    "\n",
    "df1 = pd.read_excel(r'../../assets/data_dictionary.xlsx', sheet_name='库表关系')\n",
    "df2 = pd.read_excel(r'../../assets/data_dictionary.xlsx', sheet_name='表字段信息')\n",
    "\n",
    "\n",
    "df1['库表名英文'] = df1['库名英文'] + '.' + df1['表英文']\n",
    "df1['库表名中文'] = df1['库名中文'] + '.' + df1['表中文']\n",
    "\n",
    "database_name = list(df1['库名中文'])\n",
    "table_name = list(df1['表中文'])\n",
    "table_description = list(df1['表描述'])\n",
    "table_name_en = list(df1['表英文'])\n",
    "database_table_ch = list(df1['库表名中文'])\n",
    "database_table_en = list(df1['库表名英文'])\n",
    "database_table_en_zs = {'库表名': database_table_en, \n",
    "                        '对应中文注释说明': table_name,\n",
    "                        '对应中文表描述': table_description}\n",
    "database_table_map = df1.set_index('库表名中文')['库表名英文'].to_dict()\n",
    "\n",
    "##### 1.将数据信息转换为json格式，并加入每个字段得数据例子 #####\n",
    "table_schema_list = []\n",
    "for table in tqdm(df1['库表名英文']):\n",
    "    table_schema = {}\n",
    "    table_name_i = table\n",
    "    table_schema[\"DB\"] = table.split('.')[0]\n",
    "    table_schema[\"table\"] = table_name_i\n",
    "    # 在df1中找到table对应的行\n",
    "    table_name_anno = df1[df1['库表名英文'] == table]\n",
    "    table_schema[\"description\"] = table_name_anno['表描述'].values[0]\n",
    "    # pandas查找对应的值\n",
    "    col_name_anno = df2[df2['table_name'] == table.split('.')[-1]]\n",
    "    col_name_anno = col_name_anno.copy()\n",
    "    # 将col_name_anno每一行变成字典\n",
    "    col_name_anno['schema'] = col_name_anno.apply(lambda row: {\"列名\": row['column_name'], \n",
    "                                                     \"中文描述\": row['column_description'],\n",
    "                                                     \"注释\": row['注释'],\n",
    "                                                     \"数据示例\": select_data_schema(make_sql_schema(row['column_name'], table_name_i))}, \n",
    "                                        axis=1)\n",
    "    \n",
    "    list_of_dicts = col_name_anno['schema'].tolist()\n",
    "    unique_dicts = []\n",
    "    seen = set()\n",
    "    for d in list_of_dicts:\n",
    "        # 将字典转换成元组\n",
    "        d_tuple = tuple(sorted(d.items()))\n",
    "        if d_tuple not in seen:\n",
    "            unique_dicts.append(d)\n",
    "            seen.add(d_tuple)\n",
    "\n",
    "    # 删除table_schema['schema']中列名为PresiderOfficialPost的字典\n",
    "    unique_dicts = [d for d in unique_dicts if d['列名'] != 'PresiderOfficialPost']\n",
    "    # 删除table_schema['schema']中列名为nan的字典\n",
    "    table_schema['schema'] = [d for d in unique_dicts if str(d['列名']) != 'nan']\n",
    "\n",
    "    table_schema_list.append(table_schema)\n",
    "\n",
    "# 将table_schema_list写入jsonl文件\n",
    "with open('my_table_schema.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for item in table_schema_list:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "\n",
    "\n",
    "##### 2. 将筛选字段值只有唯一一个的字段从shema中删除（这里写的冗余了，这步可以和上一步结合起来） ######\n",
    "table_schema_list = []\n",
    "# 读取jsonl文件\n",
    "with open('my_table_schema.jsonl', 'r', encoding='utf-8') as file:\n",
    "    content = [json.loads(line) for line in file]\n",
    "\n",
    "for table_schema in tqdm(content):\n",
    "    _table = {\n",
    "    'DB': table_schema['DB'],\n",
    "    'table': table_schema['table'],\n",
    "    'description': table_schema['description'],\n",
    "    'schema': []\n",
    "    }\n",
    "    table_name_i = table_schema['table']\n",
    "    col_schema = table_schema['schema']\n",
    "    for col_ in col_schema:\n",
    "        if col_['列名'] == 'ID':\n",
    "            continue\n",
    "        _data = get_value(col_['列名'], table_name_i)\n",
    "        if _data:\n",
    "            _table['schema'].append(col_)\n",
    "    table_schema_list.append(_table)\n",
    "        \n",
    "\n",
    "# 将table_schema_list写入jsonl文件\n",
    "with open('my_table_schema.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for item in table_schema_list:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 根据题目提供的数据表结构生成表之间的关系"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def find_foreign(text):\n",
    "    max_attempts = 3\n",
    "    for attempt in range(1, max_attempts + 1):\n",
    "        json_pattern = r\"【FOREIGN KEY】/\\n(.*?)\\n/【FOREIGN KEY】\"\n",
    "        match = re.search(json_pattern, text, re.DOTALL)\n",
    "        if not match:\n",
    "            return None\n",
    "\n",
    "        if match:\n",
    "            json_string = match.group(1) if match.lastindex == 1 else match.group(0)\n",
    "            # Remove Markdown formatting if present\n",
    "            json_string = json_string.replace(\"```【FOREIGN KEY】/\\n\", \"\").replace(\"\\n/【FOREIGN KEY】\", \"\")\n",
    "            return json_string\n",
    "\n",
    "\n",
    "def get_foreign(description):\n",
    "    prompt = '''\n",
    "    你是一个乐于解答各种问题的助手，你的任务是为用户提供专业、准确、有见地的建议。\n",
    "用户会给你一个数据库表中的FOREIGN KEY信息，你需要以下面的格式输出FOREIGN KEY：\n",
    "【FOREIGN KEY】/\n",
    "表名.字段名\n",
    "/【FOREIGN KEY】\n",
    "\n",
    "如果用户没有提供FOREIGN KEY信息，你需要输出：\n",
    "【没有关联信息】\n",
    "\n",
    "例子1：律师事务所企业编号(LawOfficeCode)：与机构基本资料表(LC_InstiArchive)中公司代码(CompanyCode)关联，得到预测机构的具体信息。\n",
    "输出：\n",
    "【FOREIGN KEY】/\n",
    "LC_InstiArchive.CompanyCode\n",
    "/【FOREIGN KEY】\n",
    "\n",
    "例子2：3212-方案部分实施，3301-已注册未发行，3302-已发行有额度，3303-已发行无额度，3304-提前终止，3305-放弃，3399-其他。\n",
    "输出：\n",
    "【没有关联信息】\n",
    "    '''\n",
    "\n",
    "    messages = [{'role': 'system', 'content': prompt}, {'role': 'user', 'content': description}]\n",
    "    aa = create_chat_completion(messages, model=MODEL_sql)\n",
    "    bb = find_foreign(aa.choices[0].message.content)\n",
    "    return bb\n",
    "\n",
    "# 读my_table_schema.jsonl\n",
    "with open(r'my_table_schema.jsonl', 'r', encoding='utf-8') as f:\n",
    "    table_schema = [json.loads(line) for line in f]\n",
    "\n",
    "df1 = pd.read_excel(r'../../assets/data_dictionary.xlsx', sheet_name='库表关系')\n",
    "df1['库表名英文'] = df1['库名英文'] + '.' + df1['表英文']\n",
    "database_table_en = list(df1['库表名英文'])\n",
    "\n",
    "\n",
    "# List of Chinese table names (keys)\n",
    "chinese_table_names = [i['table'] for i in table_schema]\n",
    "\n",
    "name_map = map_chinese_to_english_tables(chinese_table_names, database_table_en)\n",
    "\n",
    "db_table_col = []\n",
    "# 循环遍历table_schema\n",
    "for table in tqdm(table_schema):\n",
    "    table_name = name_map.get(table['table'])\n",
    "    for column in table[\"schema\"]:\n",
    "        column_name = column[\"列名\"]\n",
    "        db_table_col.append(f\"{table_name}.{column_name}\")\n",
    "\n",
    "foreigns = []\n",
    "# 循环遍历table_schema\n",
    "for table in tqdm(table_schema):\n",
    "    table_name = name_map.get(table['table'])\n",
    "    for column in table[\"schema\"]:\n",
    "        column_name = column[\"列名\"]\n",
    "        description = column[\"注释\"]\n",
    "        if str(description) == \"nan\":\n",
    "            continue\n",
    "        foreign = get_foreign(description)\n",
    "        if foreign:\n",
    "            _database = [i for i in db_table_col if \".\"+foreign in i]\n",
    "            if len(_database) == 1:\n",
    "                _database = _database[0]\n",
    "                foreigns.append(f\"{table_name}.{column_name}={_database}\")\n",
    "            else:\n",
    "                print(description)\n",
    "\n",
    "# 保存foreigns\n",
    "with open(\"foreigns.txt\", \"w\") as f:\n",
    "    for foreign in foreigns:\n",
    "        f.write(foreign + \"\\n\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 LLM生成关键词的别名"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df1 = pd.read_excel(r'../../assets/data_dictionary.xlsx', sheet_name='库表关系')\n",
    "df2 = pd.read_excel(r'../../assets/data_dictionary.xlsx', sheet_name='表字段信息')\n",
    "df1['库表名英文'] = df1['库名英文'] + '.' + df1['表英文']\n",
    "df1['库表名中文'] = df1['库名中文'] + '.' + df1['表中文']\n",
    "\n",
    "database_name = list(df1['库名中文'])\n",
    "table_name = list(df1['表中文'])\n",
    "table_name_en = list(df1['表英文'])\n",
    "database_table_ch = list(df1['库表名中文'])\n",
    "database_table_en = list(df1['库表名英文'])\n",
    "database_table_en_zs = {'库表名': database_table_en, '对应中文注释说明': table_name}\n",
    "database_table_map = df1.set_index('库表名中文')['库表名英文'].to_dict()\n",
    "\n",
    "database_L_zh = []\n",
    "for i in table_name_en:\n",
    "    df3 = df2[df2['table_name'] == i]\n",
    "    name = df1[df1['表英文'] == i]['库表名英文'].iloc[0]\n",
    "    column_name = list(df3['column_name'])\n",
    "    column_name_zh = list(df3['column_description'])\n",
    "    column_name_2 = list(df3['注释'].dropna())\n",
    "\n",
    "    dict_2 = {'数据表名': name, '列名': column_name, '列名中文描述': column_name_zh, '注释': column_name_2}\n",
    "    database_L_zh.append(dict_2)\n",
    "\n",
    "L_num = []\n",
    "for items in database_L_zh:\n",
    "    L_num += items['列名中文描述']\n",
    "\n",
    "# Get unique column descriptions\n",
    "L_num_new = [item for item, count in Counter(L_num).items() if count == 1]\n",
    "\n",
    "# Drop NaN if any\n",
    "series_num = pd.Series(L_num_new)\n",
    "L_num_new = list(series_num.dropna())\n",
    "\n",
    "# Remove known irrelevant items\n",
    "irrelevant_items = ['年度', '占比']\n",
    "for irr in irrelevant_items:\n",
    "    if irr in L_num_new:\n",
    "        L_num_new.remove(irr)\n",
    "\n",
    "items_another = {} \n",
    "sensitive_term = []\n",
    "for item in tqdm(L_num_new):\n",
    "    messages = [{'role': 'system', 'content': '你是一个乐于解答各种问题的助手，你的任务是为用户提供专业、准确、有见地的建议。'}, \n",
    "                {'role': 'user', 'content': item + \"\"\" 请把这个词在口头语的说法尽量多的写出来，可以写长、写短，用json格式输出，格式如下{\"short\":[], \"medium\":[], \"long\":[]}\"\"\"}]\n",
    "    try:\n",
    "        aa = create_chat_completion(messages, model=MODEL_sql)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(item)\n",
    "        sensitive_term.append(item)\n",
    "        items_another[item] = [item]\n",
    "        continue\n",
    "    bb = find_json(aa.choices[0].message.content)\n",
    "    \n",
    "    if not isinstance(bb, dict):\n",
    "        print(item)\n",
    "        sensitive_term.append(item)\n",
    "        items_another[item] = [item]\n",
    "        continue\n",
    "\n",
    "    bb_list = [item]\n",
    "    # 遍历bb字典\n",
    "    for key, value in bb.items():\n",
    "        bb_list.extend(value)\n",
    "    items_another[item] = list(set(bb_list))\n",
    "\n",
    "# 加入一些模型敏感词\n",
    "items_another[\"联系人电话\"] = [\n",
    "        \"联系人电话\",\n",
    "        \"联系人\",\n",
    "        \"电话号码\",\n",
    "        \"联系号码\",\n",
    "        \"联系人的电话号码\",\n",
    "        \"联系人的电话\"\n",
    "    ]\n",
    "\n",
    "items_another[\"信息披露网址\"] = [\n",
    "        \"信息披露网址\",\n",
    "        \"信息披露网站\"\n",
    "    ]\n",
    "\n",
    "items_another[\"董秘电话\"] = [\n",
    "        \"董秘电话\",\n",
    "        \"董秘\",\n",
    "        \"董事会秘书\",\n",
    "        \"董事会秘书电话\",\n",
    "        \"董事会秘书的联系电话\",\n",
    "        \"董事会秘书的联系电话\"\n",
    "    ]\n",
    "\n",
    "items_another[\"预收账款/营业收入TTM(%)\"] = [\n",
    "        \"预收账款/营业收入TTM(%)\",\n",
    "        \"预收账款/营业收入TTM\",\n",
    "        \"预收/营业\"\n",
    "    ]\n",
    "\n",
    "items_another[\"信托公司持股比例(%)\"] = [\n",
    "        \"信托公司持股比例(%)\",\n",
    "        \"信托公司持股比例\",\n",
    "        \"信托持股\"\n",
    "    ]\n",
    "\n",
    "items_another[\"增发股份上市日期\"] = [\n",
    "        \"增发股份上市日期\",\n",
    "        \"增发股份上市日\"\n",
    "    ]\n",
    "\n",
    "items_another[\"今开盘(元)\"] = [\n",
    "        \"今开盘(元)\",\n",
    "        \"今开\",\n",
    "        \"今开盘\",\n",
    "        \"开盘价\",\n",
    "        \"开盘\"\n",
    "    ]\n",
    "\n",
    "items_another[\"今开盘(元)\"] = [\n",
    "        \"今开盘(元)\",\n",
    "        \"今开\",\n",
    "        \"今开盘\",\n",
    "        \"开盘价\",\n",
    "        \"开盘\"\n",
    "    ]\n",
    "\n",
    "items_another[\"复牌时间\"] = [\n",
    "        \"复牌时间\",\n",
    "        \"复牌\",\n",
    "        \"复牌日期\",\n",
    "        \"复牌日\",\n",
    "        \"复牌时刻\"\n",
    "    \n",
    "    ]\n",
    "\n",
    "items_another[\"公司类别描述\"] = [\n",
    "        \"公司类别描述\",\n",
    "        \"公司类别\",\n",
    "        \"公司类别说明\"\n",
    "    ]\n",
    "\n",
    "items_another[\"近三个月成交量(股)\"] = [\n",
    "        \"近三个月成交量(股)\",\n",
    "        \"近三个月成交\",\n",
    "        \"近三个月成交股数\",\n",
    "        \"近三个月成交数\",\n",
    "        \"近三个月成交数量\",\n",
    "        \"近三个月成交股\",\n",
    "        \"近三个月成交量\",\n",
    "        \"近三个月成交额\"\n",
    "    ]\n",
    "\n",
    "items_another[\"开盘价\"] = [\n",
    "        \"开盘价\",\n",
    "        \"开盘\"\n",
    "    ]\n",
    "\n",
    "items_another[\"基金代码\"] = [\n",
    "        \"基金代码\"\n",
    "    ]\n",
    "\n",
    "# 保存json\n",
    "with open('items_another.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(items_another, f, ensure_ascii=False, indent=4)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 推理\n",
    "## 3.1 读取预处理中的所有数据"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "question_data_path = '../../assets/question.json'\n",
    "df1 = pd.read_excel('../../assets/data_dictionary.xlsx', sheet_name='库表关系')\n",
    "df2 = pd.read_excel('../../assets/data_dictionary.xlsx', sheet_name='表字段信息')\n",
    "df1['库表名英文'] = df1['库名英文'] + '.' + df1['表英文']\n",
    "df1['库表名中文'] = df1['库名中文'] + '.' + df1['表中文']\n",
    "\n",
    "database_name = list(df1['库名中文'])\n",
    "table_name = list(df1['表中文'])\n",
    "table_name_en = list(df1['表英文'])\n",
    "database_table_ch = list(df1['库表名中文'])\n",
    "database_table_en = list(df1['库表名英文'])\n",
    "database_table_en_zs = {'库表名': database_table_en, '对应中文注释说明': table_name}\n",
    "database_table_map = df1.set_index('库表名中文')['库表名英文'].to_dict()\n",
    "\n",
    "database_L = []\n",
    "database_L_zh = []\n",
    "for i in table_name_en:\n",
    "    df3 = df2[df2['table_name'] == i]\n",
    "    name = df1[df1['表英文'] == i]['库表名英文'].iloc[0]\n",
    "    column_name = list(df3['column_name'])\n",
    "    column_name_zh = list(df3['column_description'])\n",
    "    column_name_2 = list(df3['注释'].dropna())\n",
    "\n",
    "    dict_1 = {'数据表名': name, '列名': column_name, '注释': column_name_2}\n",
    "    dict_2 = {'数据表名': name, '列名': column_name, '列名中文描述': column_name_zh, '注释': column_name_2}\n",
    "    database_L.append(dict_1)\n",
    "    database_L_zh.append(dict_2)\n",
    "\n",
    "# 读取上面生成的表结构文件\n",
    "file_path = 'my_table_schema.jsonl'\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    content = [json.loads(line) for line in file]\n",
    "input_text = content\n",
    "\n",
    "# 读取上面生成的表联系文件\n",
    "foreigns_path = 'foreigns.txt'\n",
    "foreigns = read_foreigns(foreigns_path)\n",
    "\n",
    "# 读取上面生成items_another.json文件\n",
    "with open('items_another.json', 'r', encoding='utf-8') as f:\n",
    "    items_another = json.load(f)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2  提取SQL，查询数据函数"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def replace_date_with_day(sql):\n",
    "    \"\"\"\n",
    "    This function replaces instances of exact date conditions in a SQL \n",
    "    statement from a format like:\n",
    "        TradingDate = 'YYYY-MM-DD'\n",
    "    to:\n",
    "        date(TradingDate) = 'YYYY-MM-DD'\n",
    "    \n",
    "    Parameters:\n",
    "        sql (str): The original SQL statement.\n",
    "        \n",
    "    Returns:\n",
    "        str: The modified SQL statement, or the original if no match is found.\n",
    "    \"\"\"\n",
    "    # Regex pattern to match patterns like: ColumnName = 'YYYY-MM-DD'\n",
    "    pattern = r\"([.\\w]+)\\s*=\\s*'(\\d{4}-\\d{2}-\\d{2})'\"\n",
    "\n",
    "    def replace_func(match):\n",
    "        column_name = match.group(1)\n",
    "        date_value = match.group(2)\n",
    "        return f\"date({column_name}) = '{date_value}'\"\n",
    "\n",
    "    new_sql = re.sub(pattern, replace_func, sql)\n",
    "\n",
    "    # If no change was made, return the original SQL\n",
    "    return new_sql if new_sql != sql else sql\n",
    "\n",
    "def select_data(sql_text):\n",
    "    \"\"\"\n",
    "    Sends the given SQL query to a specified endpoint and returns the JSON response.\n",
    "    \n",
    "    Parameters:\n",
    "        sql_text (str): The SQL query to be executed.\n",
    "        \n",
    "    Returns:\n",
    "        str: The JSON response from the API, formatted with indentation.\n",
    "    \"\"\"\n",
    "    url = \"https://comm.chatglm.cn/finglm2/api/query\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f'Bearer {Access_Token}'\n",
    "    }\n",
    "    data = {\n",
    "        \"sql\": sql_text.replace(\"`\", \"\"),  # e.g. SELECT * FROM constantdb.secumain LIMIT 10\n",
    "        \"limit\": 15\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    try:\n",
    "        result = json.dumps(response.json(), indent=2, ensure_ascii=False)\n",
    "        if \"查询执行失败\" in result:\n",
    "            return result, \"查询执行失败，请检查SQL语句是否正确\"\n",
    "        result_json = response.json()['data']\n",
    "        if len(result_json) >= 15:\n",
    "            return result, \"由于性能问题，数据库最多只能返回15条数据，请用聚合函数count、sum、avg、max、min等来查询\"\n",
    "        return result, \"\"\n",
    "    except json.decoder.JSONDecodeError:\n",
    "        return str(response), \"查询失败，请重新生成SQL语句\"\n",
    "        # raise Exception(\"API response is not in JSON format.\")\n",
    "    \n",
    "def extract_sql(text):\n",
    "    \"\"\"\n",
    "    Extracts an SQL statement from a block of text enclosed in triple backticks:\n",
    "        ```sql\n",
    "        SELECT ...\n",
    "        ```\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): The full text containing an SQL statement.\n",
    "        \n",
    "    Returns:\n",
    "        str: The extracted SQL statement, or a message if not found.\n",
    "    \"\"\"\n",
    "    sql_pattern = re.compile(r'```sql(.*?)```', re.DOTALL)\n",
    "    match = sql_pattern.search(text)\n",
    "    if match:\n",
    "        # Strip leading and trailing whitespace from the matched SQL\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        return \"No SQL statement found.\"\n",
    "\n",
    "def to_select(text,):\n",
    "    \"\"\"\n",
    "    High-level function that:\n",
    "      1. Extracts SQL from the given text.\n",
    "      2. Optimizes the extracted SQL by converting date columns to 'date(...)'.\n",
    "      3. Executes the optimized SQL through select_data and returns the result.\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): The input text containing an SQL statement.\n",
    "        \n",
    "    Returns:\n",
    "        str: The JSON response from the SQL query.\n",
    "    \"\"\"\n",
    "    sql_statement = extract_sql(text)\n",
    "    print('***********Extracted SQL****************')\n",
    "    print(sql_statement)\n",
    "    with open('log.txt', 'a', encoding='utf-8') as f:\n",
    "        f.write(sql_statement + '\\n')\n",
    "    print('***********Extracted SQL****************')\n",
    "    # 写入log文件\n",
    "    with open('log.txt', 'a', encoding='utf-8') as f:\n",
    "        f.write('***********Extracted SQL****************' + '\\n')\n",
    "    if 'No SQL statement found.' in sql_statement:\n",
    "        return \"未找到SQL语句，请重新生成sql。或者在提示我：<全部完成，答案如下>后，直接回答问题。\", \"\", sql_statement\n",
    "    optimized_sql = replace_date_with_day(sql_statement)\n",
    "    result, intro_str = select_data(optimized_sql)\n",
    "    return result, intro_str, optimized_sql"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 定义对话逻辑\n",
    "### 3.2.1 问题的预处理"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import requests\n",
    "# 下面是对模型来说较难的查询关键词\n",
    "examples = {\n",
    "    \"查询美股公司信息\": \"查询美股公司，要同时查询USStockDB.US_CompanyInfo 和 ConstantDB.US_SecuMain中的信息,不要遗漏\",\n",
    "    \"查询港股公司信息\": \"查询港股公司，要同时查询HKStockDB.HK_StockArchives 和 ConstantDB.HK_SecuMain中的信息,不要遗漏\",\n",
    "    \"查询的表名中有DailyQuote\": \"查询AStockMarketQuotesDB.QT_DailyQuote, USStockDB.US_DailyQuote中的特定公司股票时，不要使用其他字段筛选特定公司，示例sql语句:SELECT * FROM AStockDailyQuote WHERE  InnerCode = 1234;\",\n",
    "    \"查询某行业市值\": \"查询某行业市值,示例sql语句:SELECT TotalMV, NegotiableMV, FreeFloatMV FROM AStockIndustryDB.LC_IndustryValuation WHERE date(TradingDay) = '2020-07-02' AND IndustryName = '风电零部件';\",\n",
    "    \"进行加减乘除数学计算\": \"使用sql进行加减乘除数学计算。\",\n",
    "    \"比例/百分比是多少\": \"查询比例/百分比是多少，要考虑加上百分号后再进行四舍五入。\",\n",
    "    \"近一个月最高价\": \"查询近一个月最高价,你写的sql语句可以优先考虑表中已有字段HighPriceRM  近一月最高价(元)\",\n",
    "    \"近一个月最低价\": \"查询近一月最低价(元),你写的sql语句直接调用已有字段LowPriceRM\",\n",
    "    \"查询某行业数量\": \"查询某行业某年数量 示例sql语句:SELECT count(*) as 风电零部件_2021 FROM AStockIndustryDB.LC_ExgIndustry where ThirdIndustryName like '%风电零部件%' and year(InfoPublDate)=2021 and IfPerformed = 1;\",\n",
    "    \"某股票/公司属于哪些行业/概念板块？\": \"查询某股票/公司属于哪些概念板块？ 示例sql语句:SELECT ConceptCode, ConceptName from AStockIndustryDB.LC_ConceptList WHERE ConceptCode IN (SELECT DISTINCT ConceptCode  FROM AStockIndustryDB.LC_COConcept WHERE InnerCode = 1167);\",\n",
    "    \"某行业/概念板块有哪些股票/公司？\": \"查询某概念板块有哪些股票/公司？ 示例sql语句:SELECT InnerCode FROM AStockIndustryDB.LC_COConcept WHERE ConceptCode = 11100021;\",\n",
    "    \"\"\"持有无限售流通A股数量\"\"\": \"\"\"特别重要一定注意，查询最新更新XXXX年年度报告，机构持有无限售流通A股数量合计InstitutionsHoldProp最多公司代码，优先使用查询sql语句，SELECT *\n",
    "                            FROM AStockShareholderDB.LC_StockHoldingSt\n",
    "                            WHERE date(EndDate) = 'XXXX-12-31'\n",
    "                              AND UpdateTime = (\n",
    "                                SELECT MAX(UpdateTime)\n",
    "                                FROM AStockShareholderDB.LC_StockHoldingSt\n",
    "                                WHERE date(EndDate) = 'XXXX-12-31'\n",
    "                              ) order by InstitutionsHoldings desc limit 1 ，XXXX代表问题查询年度，sql语句禁止出现group by InnerCode;\n",
    "\n",
    "                              查询最新更新XXXX年年度报告,公司机构持有无限售流通A股比例合计InstitutionsHoldProp是多少,优先使用查询sql语句，SELECT InstitutionsHoldProp\n",
    "                            FROM AStockShareholderDB.LC_StockHoldingSt\n",
    "                            WHERE date(EndDate) = 'XXXX-12-31'\n",
    "                              AND UpdateTime = (\n",
    "                                SELECT MAX(UpdateTime)\n",
    "                                FROM AStockShareholderDB.LC_StockHoldingSt\n",
    "                                WHERE date(EndDate) = 'XXXX-12-31'\n",
    "                              ) order by InstitutionsHoldings desc limit 1 ，XXXX代表问题查询年度，sql语句禁止出现group by InnerCode;\"\"\",\n",
    "    \"xxx指标 新高 最多的交易日\": \"\"\"\n",
    "    xxx指标 新高 最多的交易日 要用AStockMarketQuotesDB.CS_StockPatterns现有字段，例子中IfHighestTVRMThree字段可以根据情况灵活调整\n",
    "        查询成交量创近一季度新高的证券数量和交易日，示例sql语句:\n",
    "            SELECT count(*) as num, TradingDay  FROM AStockMarketQuotesDB.CS_StockPatterns where  IfHighestTVRMThree=1 group by TradingDay ORDER BY num DESC limit 1;\n",
    "        查询某日成交量创近一季度新高的证券，示例sql语句:\n",
    "            SELECT InnerCode, TradingDay  FROM AStockMarketQuotesDB.CS_StockPatterns where  IfHighestTVRMThree=1 and date(TradingDay) = '2021-12-23';\n",
    "\"\"\",\n",
    "    \"新高\": \"\"\"新高 要用AStockMarketQuotesDB.CS_StockPatterns现有字段\n",
    "        查询今天是2021年01月01日，创近半年新高的股票有几只。示例sql语句:SELECT count(*)  FROM AStockMarketQuotesDB.CS_StockPatterns\n",
    "                where  IfHighestHPriceRMSix=1 and date(TradingDay)='2021-01-01';\n",
    "        判断某日 YY-MM-DD  InnerCode XXXXXX 是否创近一周的新高，查询结果1代表是,IfHighestHPriceRW字段可以根据情况灵活调整  SELECT   InnerCode,TradingDay,IfHighestHPriceRW  FROM AStockMarketQuotesDB.CS_StockPatterns\n",
    "where  date(TradingDay)='2021-12-20' and InnerCode = '311490'\"\"\",\n",
    "    \"成交额\": \"\"\"查询这家公司一周内成交额是多少。示例sql语句:SELECT TurnoverValueRW AS TurnoverValueWan\n",
    "FROM AStockMarketQuotesDB.QT_StockPerformance\n",
    "WHERE InnerCode = 1289 AND date(TradingDay) = '2021-06-17';\"\"\",\n",
    "    \"半年度报告\": \"\"\"查询XXXX年半年度报告的条件为：year(EndDate) = XXXX and InfoSource='半年度报告'\"\"\",\n",
    "    \n",
    "}\n",
    "\n",
    "def exec_sql_s(sql, limit = 10):\n",
    "    \"\"\"\n",
    "    Execute a given SQL query on a remote endpoint and return the result.\n",
    "    Uses 'Access_Token' for authorization and limits the result to 10 rows.\n",
    "\n",
    "    Parameters:\n",
    "        sql (str): The SQL query to be executed.\n",
    "\n",
    "    Returns:\n",
    "        list: The query result as a list of rows (dictionaries), or None if not found.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"Authorization\": f'Bearer {Access_Token}',\n",
    "        \"Accept\": \"application/json\"\n",
    "    }\n",
    "    url = \"https://comm.chatglm.cn/finglm2/api/query\"\n",
    "\n",
    "    response = requests.post(url, headers=headers, json={\n",
    "        \"sql\": sql.replace(\"`\", \"\"),\n",
    "        \"limit\": limit\n",
    "    })\n",
    "    response_json = response.json()\n",
    "\n",
    "    # If there's no 'data' field, print the full response for debugging\n",
    "    if 'data' not in response_json:\n",
    "        print(response_json)\n",
    "        # 写入log文件\n",
    "        with open('log.txt', 'a', encoding='utf-8') as f:\n",
    "            f.write(str(response_json) + '\\n')\n",
    "        if response_json['detail'] == 'Invalid authentication credentials':\n",
    "            raise Exception('Invalid authentication credentials')\n",
    "\n",
    "    # Return 'data' if present\n",
    "    return response_json.get('data', None)\n",
    "\n",
    "def process_question(question, model):\n",
    "    \"\"\"\n",
    "    Given a question, run it through a prompt to perform Named Entity Recognition (NER),\n",
    "    extract entities (公司名称，代码，基金名称，概念名称，人名), parse the assistant's JSON response,\n",
    "    and process the items to retrieve relevant information from the database.\n",
    "\n",
    "    Parameters:\n",
    "        question (str): The user question.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (res, tables) where\n",
    "               res (str) - Processed result details as a string.\n",
    "               tables (list) - List of tables involved in the final result.\n",
    "    \"\"\"\n",
    "    prompt = '''\n",
    "    你将会进行命名实体识别任务，并输出实体json，主要识别以下几种实体：\n",
    "    公司名称，代码，基金名称，概念名称，人名。\n",
    "\n",
    "    其中，公司名称可以是全称，简称，拼音缩写，代码包含股票代码和基金代码，基金名称包含债券型基金，\n",
    "    以下是几个示例：\n",
    "    user:唐山港集团股份有限公司是什么时间上市的（回答XXXX-XX-XX）\n",
    "    当年一共上市了多少家企业？\n",
    "    这些企业有多少是在北京注册的？\n",
    "    assistant:```json\n",
    "    [{\"公司名称\":\"唐山港集团股份有限公司\"}]\n",
    "    ```\n",
    "    user:JD的职工总数有多少人？\n",
    "    该公司披露的硕士或研究生学历（及以上）的有多少人？\n",
    "    20201月1日至年底退休了多少人？\n",
    "    assistant:```json\n",
    "    [{\"公司名称\":\"JD\"}]\n",
    "    ```\n",
    "    user:600872的全称、A股简称、法人、法律顾问、会计师事务所及董秘是？\n",
    "    该公司实控人是否发生改变？如果发生变化，什么时候变成了谁？是哪国人？是否有永久境外居留权？（回答时间用XXXX-XX-XX）\n",
    "    assistant:```json\n",
    "    [{\"代码\":\"600872\"}]\n",
    "    ```\n",
    "    user:华夏鼎康债券A在2019年的分红次数是多少？每次分红的派现比例是多少？\n",
    "    基于上述分红数据，在2019年最后一次分红时，如果一位投资者持有1000份该基金，税后可以获得多少分红收益？\n",
    "    assistant:```json\n",
    "    [{\"基金名称\":\"华夏鼎康债券A\"}]\n",
    "    ```\n",
    "    user:化工纳入过多少个子类概念？\n",
    "    assistant:```json\n",
    "    [{\"概念名称\":\"化工\"}]\n",
    "    ```\n",
    "    user:李一硕管理的基金中，规模最大的是哪一个？\n",
    "    assistant:```json\n",
    "    [{\"人名\":\"李一硕\"}]\n",
    "    ```\n",
    "    '''\n",
    "\n",
    "    messages = [{'role': 'system', 'content': prompt}, {'role': 'user', 'content': question}]\n",
    "    for _ in range(3):\n",
    "        aa = create_chat_completion(messages, model)\n",
    "        bb = find_json(aa.choices[0].message.content)\n",
    "        # if bb is \n",
    "        if isinstance(bb, list):\n",
    "            break\n",
    "    return process_items(bb)\n",
    "\n",
    "def process_items(item_list):\n",
    "    \"\"\"\n",
    "    Given a list of items (dictionaries) from JSON extraction, attempt to process each based on its key:\n",
    "    - If key is '基金名称' or '公司名称', use process_company_name.\n",
    "    - If key is '代码', use process_code.\n",
    "    - If key is '人名', use process_human.\n",
    "    - If key is '概念名称', use process_concept.\n",
    "    - Otherwise, print an unrecognized key message.\n",
    "\n",
    "    Parameters:\n",
    "        item_list (list): A list of dictionaries like [{\"公司名称\": \"XX公司\"}, {\"代码\":\"600872\"}].\n",
    "\n",
    "    Returns:\n",
    "        tuple: (res, tables)\n",
    "               res (str): A formatted string showing what was found.\n",
    "               tables (list): A list of table names where matches were found.\n",
    "    \"\"\"\n",
    "    res_list = []\n",
    "    lsh_res_list = []\n",
    "    concept_list = []\n",
    "    if isinstance(item_list, str):\n",
    "        return item_list, [], []\n",
    "    \n",
    "    for item in item_list:\n",
    "        try:\n",
    "            key, value = list(item.items())[0]\n",
    "        except:\n",
    "            continue\n",
    "        if key in [\"基金名称\", \"公司名称\"]:\n",
    "            r, lsh_r = process_company_name(value)\n",
    "            res_list.extend(r)\n",
    "            lsh_res_list.extend(lsh_r)\n",
    "        elif key == \"代码\":\n",
    "            res_list.extend(process_code(value))\n",
    "        elif key == \"概念名称\":\n",
    "            concept_list.extend(process_concept(value))\n",
    "        elif key == \"人名\":\n",
    "            lsh_res_list.extend(process_human(value))\n",
    "\n",
    "        else:\n",
    "            print(f\"无法识别的键：{key}\")\n",
    "            # 写入log文件\n",
    "            with open(\"log.txt\", \"a\", encoding='utf-8') as f:\n",
    "                f.write(f\"无法识别的键：{key}\\n\")\n",
    "\n",
    "    if concept_list:\n",
    "        concept_list.append(\"行业概念中，ConceptNames是SubclassName的子类，SubclassName是ClassName的子类；\" + \n",
    "                            \"SecondIndustryName是FirstIndustryName的子类，ThirdIndustryName是SecondIndustryName的子类，FourthIndustryName是ThirdIndustryName的子类；\")\n",
    "\n",
    "    # Filter out empty results\n",
    "    res_list_ = []\n",
    "    res_str = []\n",
    "    for i in res_list:\n",
    "        if i:\n",
    "            if str(i) not in res_str:\n",
    "                res_str.append(str(i))\n",
    "                res_list_.append(i)\n",
    "\n",
    "    res_list = res_list_\n",
    "    res = ''\n",
    "    tables = []\n",
    "    for result_data, table_name in res_list:\n",
    "        tables.append(table_name)\n",
    "        res += f\"预处理程序通过表格：{table_name} 查询到以下内容：\\n {json.dumps(result_data, ensure_ascii=False, indent=1)} \\n\"\n",
    "    \n",
    "    for r in lsh_res_list:\n",
    "        res += f\"\\n {r}\"\n",
    "    return res, tables, concept_list\n",
    "\n",
    "def process_company_name(value):\n",
    "    \"\"\"\n",
    "    Given a company name (or related keyword), search in three tables:\n",
    "    ConstantDB.SecuMain, ConstantDB.HK_SecuMain, ConstantDB.US_SecuMain.\n",
    "\n",
    "    Attempts to match various company-related fields (e.g., ChiName, EngName, etc.)\n",
    "    and returns all matching results along with the table where they were found.\n",
    "\n",
    "    Parameters:\n",
    "        value (str): The company name or related string to match.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples (result, table) where result is the matched data and table is the table name.\n",
    "              If no matches found, prints a message and returns an empty list.\n",
    "    \"\"\"\n",
    "    res_lst = []\n",
    "    lsh_res_lst = []\n",
    "    tables = ['ConstantDB.SecuMain', 'ConstantDB.HK_SecuMain', 'ConstantDB.US_SecuMain']\n",
    "    columns_to_match = ['CompanyCode', 'SecuCode', 'ChiName', 'ChiNameAbbr',\n",
    "                        'EngName', 'EngNameAbbr', 'SecuAbbr', 'ChiSpelling']\n",
    "    columns_to_select = ['InnerCode', 'CompanyCode', 'SecuCode', 'ChiName', 'ChiNameAbbr',\n",
    "                         'EngName', 'EngNameAbbr', 'SecuAbbr', 'ChiSpelling']\n",
    "\n",
    "    # Escape single quotes to prevent SQL injection\n",
    "    value = value.replace(\"'\", \"''\")\n",
    "\n",
    "    for table in tables:\n",
    "        # For the US table, remove columns that may not be available\n",
    "        local_match_cols = columns_to_match.copy()\n",
    "        local_select_cols = columns_to_select.copy()\n",
    "        if 'US' in table:\n",
    "            if 'ChiNameAbbr' in local_match_cols:\n",
    "                local_match_cols.remove('ChiNameAbbr')\n",
    "            if 'ChiNameAbbr' in local_select_cols:\n",
    "                local_select_cols.remove('ChiNameAbbr')\n",
    "            if 'EngNameAbbr' in local_match_cols:\n",
    "                local_match_cols.remove('EngNameAbbr')\n",
    "            if 'EngNameAbbr' in local_select_cols:\n",
    "                local_select_cols.remove('EngNameAbbr')\n",
    "\n",
    "        # Build the WHERE clause with OR conditions for each column\n",
    "        match_conditions = [f\"{col} like '%{value}%'\" for col in local_match_cols]\n",
    "        where_clause = ' OR '.join(match_conditions)\n",
    "\n",
    "        sql = f\"\"\"\n",
    "        SELECT {', '.join(local_select_cols)}\n",
    "        FROM {table}\n",
    "        WHERE {where_clause}\n",
    "        \"\"\"\n",
    "        result = exec_sql_s(sql)\n",
    "        if result:\n",
    "            res_lst.append((result, table))\n",
    "    else:\n",
    "        # The 'else' clause in a for loop runs only if no 'break' was encountered.\n",
    "        # Here it just prints if no results were found.\n",
    "        if not res_lst:\n",
    "            print(f\"未在任何表中找到公司名称为 {value} 的信息。\")\n",
    "            # 写入log文件\n",
    "            with open('log.txt', 'a', encoding='utf-8') as f:\n",
    "                f.write(f\"未在任何表中找到公司名称为 {value} 的信息。\\n\")\n",
    "            \n",
    "    return res_lst, lsh_res_lst\n",
    "\n",
    "def process_code(value):\n",
    "    \"\"\"\n",
    "    Given a code (e.g., a stock code), search the three tables and return matches.\n",
    "\n",
    "    Parameters:\n",
    "        value (str): The code to search for.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples (result, table) if found, else empty.\n",
    "    \"\"\"\n",
    "    res_lst = []\n",
    "    tables = ['ConstantDB.SecuMain', 'ConstantDB.HK_SecuMain', 'ConstantDB.US_SecuMain']\n",
    "    columns_to_select = ['InnerCode', 'CompanyCode', 'SecuCode', 'ChiName', 'ChiNameAbbr',\n",
    "                         'EngName', 'EngNameAbbr', 'SecuAbbr', 'ChiSpelling']\n",
    "\n",
    "    value = value.replace(\"'\", \"''\")  # Escape single quotes\n",
    "\n",
    "    for table in tables:\n",
    "        local_select_cols = columns_to_select.copy()\n",
    "        if 'US' in table:\n",
    "            if 'ChiNameAbbr' in local_select_cols:\n",
    "                local_select_cols.remove('ChiNameAbbr')\n",
    "            if 'EngNameAbbr' in local_select_cols:\n",
    "                local_select_cols.remove('EngNameAbbr')\n",
    "\n",
    "        sql = f\"\"\"\n",
    "        SELECT {', '.join(local_select_cols)}\n",
    "        FROM {table}\n",
    "        WHERE SecuCode = '{value}'\n",
    "        \"\"\"\n",
    "        result = exec_sql_s(sql)\n",
    "        if result:\n",
    "            res_lst.append((result, table))\n",
    "    else:\n",
    "        if not res_lst:\n",
    "            print(f\"未在任何表中找到代码为 {value} 的信息。\")\n",
    "            # 写入log文件\n",
    "            with open('log.txt', 'a', encoding='utf-8') as f:\n",
    "                f.write(f\"未在任何表中找到代码为 {value} 的信息。\\n\")\n",
    "\n",
    "    return res_lst\n",
    "\n",
    "def process_concept(value):\n",
    "    \"\"\"\n",
    "    Process the concept value and return the result list.\n",
    "    \"\"\"\n",
    "    res_lst = [\"进行where条件查询时，请充分考虑下面的条件：\"]\n",
    "    res_lst = []\n",
    "    tables = {'AStockIndustryDB.LC_ExgIndustry': ['Industry', 'FirstIndustryName', 'SecondIndustryName', 'ThirdIndustryName', 'FourthIndustryName'], \n",
    "              'AStockIndustryDB.LC_ExgIndChange': ['Industry', 'FirstIndustryName', 'SecondIndustryName', 'ThirdIndustryName', 'FourthIndustryName'], \n",
    "              'AStockIndustryDB.LC_IndustryValuation': ['IndustryName'],\n",
    "              'AStockIndustryDB.LC_IndFinIndicators': ['IndustryName'], \n",
    "              'AStockIndustryDB.LC_ConceptList': ['ClassName', 'SubclassName', 'ConceptName']}\n",
    "\n",
    "    value = value.replace(\"'\", \"''\")  # Escape single quotes\n",
    "\n",
    "    for table, cols in tables.items():\n",
    "        match_conditions = [f\"{col} = '{value}'\" for col in cols]\n",
    "        where_clause = ' OR '.join(match_conditions)\n",
    "        sql = f\"\"\"\n",
    "        SELECT {', '.join(cols)}\n",
    "        FROM {table}\n",
    "        WHERE {where_clause}\n",
    "        \"\"\"\n",
    "        result = exec_sql_s(sql, limit = 1)\n",
    "        if result:\n",
    "            res_lst.append(f\"{table}表中存在行业<{value}>，部分数据如下：{result} \" )\n",
    "\n",
    "    return res_lst\n",
    "\n",
    "def process_human(value):\n",
    "    \"\"\"\n",
    "    Process the human value and return the result list.\n",
    "    \"\"\"\n",
    "    res_lst = [\"进行where条件查询时，请充分考虑下面的条件：\"]\n",
    "    res_lst = []\n",
    "    tables = {\n",
    "            'AStockBasicInfoDB.LC_StockArchives': ['GeneralManager', 'LegalConsultant'], \n",
    "            'AStockShareholderDB.LC_SHTypeClassifi': ['SHName', 'SHCode'], \n",
    "              'AStockShareholderDB.LC_MainSHListNew': ['SHList', 'GDID'], \n",
    "              'AStockShareholderDB.LC_Mshareholder': ['MSHName', 'GDID'],\n",
    "              'AStockShareholderDB.LC_ActualController': ['ControllerName'], \n",
    "              'AStockShareholderDB.LC_ShareTransfer': ['TransfererName', 'ReceiverName'], \n",
    "              'AStockShareholderDB.LC_ShareFP': ['FPSHName', 'ReceiverName'], \n",
    "              'AStockShareholderDB.LC_ShareFPSta': ['FPSHName'], \n",
    "              'AStockShareholderDB.LC_LegalDistribution': ['InvestorName', 'StandardInvestorName', 'StandardAquirerName'], \n",
    "              'AStockShareholderDB.LC_NationalStockHoldSt': ['SHName'], \n",
    "              'CreditDB.LC_ViolatiParty': ['PartyName'],\n",
    "              'AStockEventsDB.LC_InvestorDetail': ['PersonalName'],\n",
    "              'AStockShareholderDB.LC_TransferPlan': ['SHName'],\n",
    "              'PublicFundDB.MF_FundArchives': ['Manager', 'InvestAdvisorCode', 'TrusteeCode'],\n",
    "              'PublicFundDB.MF_InvestAdvisorOutline': ['InvestAdvisorName', 'InvestAdvisorAbbrName', 'LegalRepr', 'GeneralManager'],\n",
    "              'InstitutionDB.LC_InstiArchive': ['InvestAdvisorName', 'TrusteeName', 'LegalPersonRepr', 'GeneralManager', 'OtherManager', 'Contactman', ],\n",
    "              }\n",
    "\n",
    "    value = value.replace(\"'\", \"''\")  # Escape single quotes\n",
    "\n",
    "    for table, cols in tables.items():\n",
    "        match_conditions = [f\"{col} like '%{value}%'\" for col in cols]\n",
    "        where_clause = ' OR '.join(match_conditions)\n",
    "        sql = f\"\"\"\n",
    "        SELECT {', '.join(cols)}\n",
    "        FROM {table}\n",
    "        WHERE {where_clause}\n",
    "        \"\"\"\n",
    "        result = exec_sql_s(sql)\n",
    "        if result:\n",
    "            res_lst.append(f\"{table}表中存在人名<{value}>，部分数据如下：{result} \" )\n",
    "\n",
    "    return res_lst\n",
    "\n",
    "def checkStockMarket(question, model):\n",
    "    \"\"\"\n",
    "    判断股票市场\n",
    "    \"\"\"\n",
    "    markets = []\n",
    "    prompt = (\n",
    "        \"请判断要回答'<<question>>'，需要查询<A股、港股、美股>中的哪几个股票市场，\"\n",
    "        \"请使用json回答\\n\"\n",
    "        \"格式如下：\\n\"\n",
    "        \"{'原因': '为什么要选择这几个股票市场', '选择的股票市场': [一个list]}\"\n",
    "    ).replace(\"<<question>>\", question)\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = create_chat_completion(messages, model)\n",
    "    answer = response.choices[0].message.content\n",
    "    try:\n",
    "        StockMarket = find_json(answer)['选择的股票市场']\n",
    "        if StockMarket == []:\n",
    "            return ['ConstantDB.SecuMain', 'ConstantDB.HK_SecuMain', 'ConstantDB.US_SecuMain']\n",
    "        \n",
    "        if 'A股' in StockMarket:\n",
    "            markets.append('ConstantDB.SecuMain')\n",
    "        if '港股' in StockMarket:\n",
    "            markets.append('ConstantDB.HK_SecuMain')\n",
    "        if '美股' in StockMarket:\n",
    "            markets.append('ConstantDB.US_SecuMain')\n",
    "    except:\n",
    "        return ['ConstantDB.SecuMain', 'ConstantDB.HK_SecuMain', 'ConstantDB.US_SecuMain']\n",
    "    return markets\n",
    "\n",
    "def find_example(question):\n",
    "    \"\"\"\n",
    "    找到与问题相关的示例问题\n",
    "    \"\"\"\n",
    "    prompt = f'''\n",
    "    用户问题：{question}\n",
    "    你是一个金融领域的专家，请根据用户问题，从以下的示例问题中找到与用户问题相关的示例问题：\n",
    "    {str([example for example in examples.keys()])}\n",
    "\n",
    "    请输出与用户问题相关的示例问题，多个问题之间用逗号隔开，例如：key1,key2,key3\n",
    "    '''\n",
    "    messages_rag = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = async_llm_chain_call(messages_rag, MODEL_rag, sampling_count=1)\n",
    "    last_response = response.choices[0].message.content\n",
    "\n",
    "    result = []\n",
    "    for key in examples.keys():\n",
    "        if key in last_response:\n",
    "            result.append(examples[key])\n",
    "    return \"\\n\".join(result)+\"\\n\"+ \"查询和时间相关的信息，如果没有返回数据，要考虑其他的时间相关列，比如InfoPublDate、EndDate、TradingDay等。\"\n",
    "\n",
    "def to_get_question_columns(question, database_L_zh):\n",
    "    \"\"\"\n",
    "    Given a question (string) and a database_L_zh (list of dicts),\n",
    "    find 列名 that correspond to 列名中文描述 mentioned in the question. \n",
    "    \n",
    "    If any matching columns are found, return a message instructing the user to \n",
    "    use these column names directly for data querying. If none are found, return an empty string.\n",
    "    \n",
    "    Parameters:\n",
    "        question (str): The input question text.\n",
    "        \n",
    "    Returns:\n",
    "        str: A message with identified column names or an empty string if none found.\n",
    "    \"\"\"\n",
    "    L_num = []\n",
    "    for items in database_L_zh:\n",
    "        L_num += items['列名中文描述']\n",
    "\n",
    "    # Get unique column descriptions\n",
    "    L_num_new = [item for item, count in Counter(L_num).items() if count == 1]\n",
    "\n",
    "    # Drop NaN if any\n",
    "    series_num = pd.Series(L_num_new)\n",
    "    L_num_new = list(series_num.dropna())\n",
    "\n",
    "    # Remove known irrelevant items\n",
    "    irrelevant_items = ['年度', '占比']\n",
    "    for irr in irrelevant_items:\n",
    "        if irr in L_num_new:\n",
    "            L_num_new.remove(irr)\n",
    "\n",
    "    matched_columns = []\n",
    "    for col_descs in L_num_new:\n",
    "        col_desc_another = items_another[col_descs]\n",
    "        for col_desc in col_desc_another:\n",
    "            # Check if the column description or its cleaned version appears in the question\n",
    "            if col_desc in question or clean_text(col_desc) in question:\n",
    "                L_dict = find_dict_by_element(database_L_zh, col_descs)\n",
    "                if not L_dict:\n",
    "                    break\n",
    "                # Create a mapping from Chinese description to English column name\n",
    "                dict_zip = dict(zip(L_dict[0]['列名中文描述'], L_dict[0]['列名']))\n",
    "                column_name = dict_zip[col_descs]\n",
    "                data_table = L_dict[0]['数据表名']\n",
    "\n",
    "                matched_columns.append({\n",
    "                    '数据库表': data_table,\n",
    "                    '列名': column_name,\n",
    "                    '列名中文含义': col_descs\n",
    "                })\n",
    "                break\n",
    "\n",
    "    if matched_columns:\n",
    "        return f\"已获得一部分数据库列名{matched_columns}，请充分利用获得的列名直接查询数据。\"\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "\n",
    "def get_foreigns(foreigns, content):\n",
    "    \"\"\"\n",
    "    处理外键关系\n",
    "    \"\"\"\n",
    "    fliter = []\n",
    "    for f in foreigns:\n",
    "        [f1, f2] = f.split('=')\n",
    "        f1_table = \".\".join(f1.strip().split('.')[0: 2])\n",
    "        f2_table = \".\".join(f2.strip().split('.')[0: 2])\n",
    "        if f1_table in content and f2_table in content:\n",
    "            fliter.append(f)\n",
    "    return fliter\n",
    "\n",
    "def table_intro(LL):\n",
    "    \"\"\"\n",
    "    对选择的表进行重点提示\n",
    "    \"\"\"\n",
    "    table_names = [i['数据表名'] for i in LL]\n",
    "    is_H = 'HKStock' in str(table_names)\n",
    "    is_A = 'AStock' in str(table_names)\n",
    "    is_US = 'USStock' in str(table_names)\n",
    "    if is_H + is_A + is_US > 1:\n",
    "        return '港股、A股（AStock开头的表）、美股信息不通用，请分别查询，不要把不同地方上市的股票公司进行join。'\n",
    "    return ''\n",
    "\n",
    "class Example:\n",
    "    def __init__(self, question, database_L_zh):\n",
    "        self.question = question\n",
    "        self.reference = find_example(question)\n",
    "        self.question_columns = to_get_question_columns(question, database_L_zh)\n",
    "\n",
    "    def to_string(self, get_reference = True, get_col_shema = True):\n",
    "        _string = \"根据参考仔细检查上一步生成的sql，如果sql有问题，则返回修改后的sql；如果没有问题则按要求继续进行下一步。\\n\"\n",
    "        if get_col_shema:\n",
    "            _string = self.question_columns\n",
    "        else:\n",
    "            _string += \"\"\n",
    "\n",
    "        if get_reference:\n",
    "            _string += \">>查询参考：\"\n",
    "            _string += self.reference\n",
    "        else:\n",
    "            _string += \"\"\n",
    "        return _string\n",
    "    "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 对话生成sql和答案"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def run_conversation(question, question_id, database_L_zh):\n",
    "\n",
    "    # 1. 选择与问题相关的库表\n",
    "    # 1.1 对数据库进行划分，区分港股、A股、美股\n",
    "\n",
    "    lc = {'库表名': ['AStockBasicInfoDB.LC_StockArchives',\n",
    "'AStockBasicInfoDB.LC_NameChange',\n",
    "'AStockBasicInfoDB.LC_Business',\n",
    "'AStockIndustryDB.LC_ExgIndustry',\n",
    "'AStockIndustryDB.LC_ExgIndChange',\n",
    "'AStockIndustryDB.LC_IndustryValuation',\n",
    "'AStockIndustryDB.LC_IndFinIndicators',\n",
    "'AStockIndustryDB.LC_COConcept',\n",
    "'AStockIndustryDB.LC_ConceptList',\n",
    "'AStockOperationsDB.LC_SuppCustDetail',\n",
    "'AStockShareholderDB.LC_SHTypeClassifi',\n",
    "'AStockShareholderDB.LC_MainSHListNew',\n",
    "'AStockShareholderDB.LC_SHNumber',\n",
    "'AStockShareholderDB.LC_Mshareholder',\n",
    "'AStockShareholderDB.LC_ActualController',\n",
    "'AStockShareholderDB.LC_ShareStru',\n",
    "'AStockShareholderDB.LC_StockHoldingSt',\n",
    "'AStockShareholderDB.LC_ShareTransfer',\n",
    "'AStockShareholderDB.LC_ShareFP',\n",
    "'AStockShareholderDB.LC_ShareFPSta',\n",
    "'AStockShareholderDB.LC_Buyback',\n",
    "'AStockShareholderDB.LC_BuybackAttach',\n",
    "'AStockShareholderDB.LC_LegalDistribution',\n",
    "'AStockShareholderDB.LC_NationalStockHoldSt',\n",
    "'AStockShareholderDB.CS_ForeignHoldingSt',\n",
    "'AStockFinanceDB.LC_AShareSeasonedNewIssue',\n",
    "'AStockFinanceDB.LC_ASharePlacement',\n",
    "'AStockFinanceDB.LC_Dividend',\n",
    "'AStockFinanceDB.LC_CapitalInvest',\n",
    "'AStockMarketQuotesDB.CS_StockCapFlowIndex',\n",
    "'AStockMarketQuotesDB.CS_TurnoverVolTecIndex',\n",
    "'AStockMarketQuotesDB.CS_StockPatterns',\n",
    "'AStockMarketQuotesDB.QT_DailyQuote',\n",
    "'AStockMarketQuotesDB.QT_StockPerformance',\n",
    "'AStockMarketQuotesDB.LC_SuspendResumption',\n",
    "'AStockFinanceDB.LC_BalanceSheetAll',\n",
    "'AStockFinanceDB.LC_IncomeStatementAll',\n",
    "'AStockFinanceDB.LC_CashFlowStatementAll',\n",
    "'AStockFinanceDB.LC_IntAssetsDetail',\n",
    "'AStockFinanceDB.LC_MainOperIncome',\n",
    "'AStockFinanceDB.LC_OperatingStatus',\n",
    "'AStockFinanceDB.LC_AuditOpinion',\n",
    "'AStockOperationsDB.LC_Staff',\n",
    "'AStockOperationsDB.LC_RewardStat',\n",
    "'AStockEventsDB.LC_Warrant',\n",
    "'AStockEventsDB.LC_Credit',\n",
    "'AStockEventsDB.LC_SuitArbitration',\n",
    "'AStockEventsDB.LC_EntrustInv',\n",
    "'AStockEventsDB.LC_Regroup',\n",
    "'AStockEventsDB.LC_MajorContract',\n",
    "'AStockEventsDB.LC_InvestorRa',\n",
    "'AStockEventsDB.LC_InvestorDetail',\n",
    "'AStockShareholderDB.LC_ESOP',\n",
    "'AStockShareholderDB.LC_ESOPSummary',\n",
    "'AStockShareholderDB.LC_TransferPlan',\n",
    "'AStockShareholderDB.LC_SMAttendInfo',\n",
    "'ConstantDB.SecuMain',\n",
    "],\n",
    "'对应中文注释说明': ['公司概况',\n",
    "'公司名称更改状况',\n",
    "'公司经营范围与行业变更',\n",
    "'公司行业划分表',\n",
    "'公司行业变更表',\n",
    "'行业估值指标',\n",
    "'行业财务指标表：各行业的成长能力、偿债能力、盈利能力和现金获取能力等',\n",
    "'概念所属公司表：记录A股上市公司所属概念信息',\n",
    "'概念板块常量表：记录A股热点概念板块信息',\n",
    "'公司供应商与客户',\n",
    "'股东类型分类表',\n",
    "'股东名单(新)',\n",
    "'股东户数',\n",
    "'大股东介绍',\n",
    "'公司实际控制人',\n",
    "'公司股本结构变动',\n",
    "'股东持股统计',\n",
    "'股东股权变动',\n",
    "'股东股权冻结和质押',\n",
    "'股东股权冻结和质押统计',\n",
    "'股份回购',\n",
    "'股份回购关联表',\n",
    "'法人配售与战略投资者',\n",
    "'A股国家队持股统计',\n",
    "'外资持股统计',\n",
    "'A股增发',\n",
    "'A股配股',\n",
    "'公司分红',\n",
    "'资金投向说明',\n",
    "'境内股票交易资金流向指标',\n",
    "'境内股票成交量技术指标',\n",
    "'股票技术形态表',\n",
    "'日行情表',\n",
    "'股票行情表现(新)',\n",
    "'停牌复牌表',\n",
    "'资产负债表_新会计准则',\n",
    "'利润分配表_新会计准则',\n",
    "'现金流量表_新会计准则',\n",
    "'公司研发投入与产出',\n",
    "'公司主营业务构成',\n",
    "'公司经营情况述评',\n",
    "'公司历年审计意见',\n",
    "'公司职工构成',\n",
    "'公司管理层报酬统计',\n",
    "'公司担保明细',\n",
    "'公司借贷明细',\n",
    "'公司诉讼仲裁明细',\n",
    "'重大事项委托理财',\n",
    "'公司资产重组明细',\n",
    "'公司重大经营合同明细',\n",
    "'投资者关系活动',\n",
    "'投资者关系活动调研明细',\n",
    "'员工持股计划',\n",
    "'员工持股计划概况',\n",
    "'股东增减持计划表',\n",
    "'股东大会出席信息',\n",
    "'证券主表,包含字段InnerCode,CompanyCode,SecuCode,ChiName,ChiNameAbbr 代表中文名称缩写,EngName,EngNameAbbr,SecuAbbr 代表 证券简称,ListedDate',\n",
    "]}\n",
    "\n",
    "    other = {'库表名': [\n",
    "'PublicFundDB.MF_FundArchives',\n",
    "'PublicFundDB.MF_FundProdName',\n",
    "'PublicFundDB.MF_InvestAdvisorOutline',\n",
    "'PublicFundDB.MF_Dividend',\n",
    "'CreditDB.LC_ViolatiParty',\n",
    "'IndexDB.LC_IndexBasicInfo',\n",
    "'IndexDB.LC_IndexComponent',\n",
    "'InstitutionDB.LC_InstiArchive',\n",
    "'ConstantDB.CT_SystemConst',\n",
    "'ConstantDB.QT_TradingDayNew',\n",
    "'ConstantDB.LC_AreaCode',\n",
    "'InstitutionDB.PS_EventStru',\n",
    "'InstitutionDB.PS_NewsSecurity'],\n",
    "'对应中文注释说明': [\n",
    "'公募基金概况',\n",
    "'公募基金产品名称',\n",
    "'公募基金管理人概况',\n",
    "'公募基金分红',\n",
    "'违规当事人处罚',\n",
    "'指数基本情况',\n",
    "'指数成份',\n",
    "'机构基本资料',\n",
    "'系统常量表',\n",
    "'交易日表(新)',\n",
    "'国家城市代码表',\n",
    "'事件体系指引表',\n",
    "'证券舆情表']}\n",
    "\n",
    "    us = {'库表名': [\n",
    "'USStockDB.US_CompanyInfo',\n",
    "'USStockDB.US_DailyQuote',\n",
    "'ConstantDB.US_SecuMain',\n",
    "],\n",
    "'对应中文注释说明': [\n",
    "'美股公司概况',\n",
    "'美股日行情',\n",
    "'美股证券主表',\n",
    "]}\n",
    "\n",
    "    hk = {'库表名': [\n",
    "'HKStockDB.HK_EmployeeChange',\n",
    "'HKStockDB.HK_StockArchives',\n",
    "'HKStockDB.CS_HKStockPerformance',\n",
    "'ConstantDB.HK_SecuMain',\n",
    "],\n",
    "'对应中文注释说明': [\n",
    "'港股公司员工数量变动表',\n",
    "'港股公司概况',\n",
    "'港股行情表现',\n",
    "'港股证券主表，包含字段InnerCode,CompanyCode,SecuCode,ChiName,ChiNameAbbr 代表中文名称缩写,EngName,EngNameAbbr,SecuAbbr 代表 证券简称,ListedDate',\n",
    "]}\n",
    "\n",
    "    content_p_1 = \"\"\"我有如下数据库表<<table_schema>>\n",
    "我想回答问题\n",
    "\"<<question>>\"\n",
    "\n",
    "请从上面数据库表中筛选出要回答问题，需要哪些数据库表，记得提示我：<需要查询的数据库表>,格式如下：\n",
    "**逐步分析选择什么表**：为什么选择这些表\n",
    "**选择的数据库表**：所选择的表。\n",
    "不要输出其他内容。\"\"\"\n",
    "\n",
    "    # 1.2 对问题进行预处理，提取问题中的关键词\n",
    "    res, tables, concept_list = process_question(question, MODEL_rag)\n",
    "\n",
    "    # 1.3 根据问题中的关键词，从数据库表中选择相关的表\n",
    "    table_schema ={'库表名': [], '对应中文注释说明': []}\n",
    "    if tables == []:\n",
    "        StockMarket = checkStockMarket(question, MODEL_rag)\n",
    "    else:\n",
    "        StockMarket = tables\n",
    "    if 'ConstantDB.HK_SecuMain' in StockMarket:\n",
    "        table_schema['库表名'].extend(hk['库表名'])\n",
    "        table_schema['对应中文注释说明'].extend(hk['对应中文注释说明'])\n",
    "    if 'ConstantDB.US_SecuMain' in StockMarket:\n",
    "        table_schema['库表名'].extend(us['库表名'])\n",
    "        table_schema['对应中文注释说明'].extend(us['对应中文注释说明'])\n",
    "    if 'ConstantDB.SecuMain' in StockMarket:\n",
    "        table_schema['库表名'].extend(lc['库表名'])\n",
    "        table_schema['对应中文注释说明'].extend(lc['对应中文注释说明'])\n",
    "    \n",
    "    table_schema['库表名'].extend(other['库表名'])\n",
    "    table_schema['对应中文注释说明'].extend(other['对应中文注释说明'])\n",
    "\n",
    "    # 1.4 通过LLM进一步选择和问题相关的表\n",
    "    content_p = content_p_1.replace('<<question>>', str(question))\\\n",
    "        .replace('<<fact_1>>', str((res, tables)))\\\n",
    "        .replace('<<table_schema>>', str(table_schema))\n",
    "    ref = Example(question=question, database_L_zh = database_L_zh)\n",
    "    content_p = content_p + ref.to_string()\n",
    "    if concept_list:\n",
    "        content_p = content_p + \"\\n行业提示：\" + str(concept_list)\n",
    "\n",
    "    messages_rag = []\n",
    "    messages_rag.append({\"role\": \"user\", \"content\": \"您好阿\"})\n",
    "    messages_rag.append({\"role\": \"user\", \"content\": content_p})\n",
    "    response = async_llm_chain_call(messages_rag, MODEL_sql, sampling_count=1)\n",
    "    table_maps = get_table_schema(question = question, database_table_en = database_table_en, table_shema = input_text)\n",
    "    LL1 = [i for i in table_maps if i.get('数据表名') in response.choices[0].message.content + ref.to_string(get_col_shema=False) + str(concept_list) + str(StockMarket)]\n",
    "    if 'ConstantDB.SecuMain' in StockMarket:\n",
    "        LL = LL1\n",
    "    else:\n",
    "        LL = [i for i in LL1 if i.get('数据表名') in str(table_schema)]\n",
    "    foreigns_choice = get_foreigns(foreigns, response.choices[0].message.content + str(StockMarket))\n",
    "    \n",
    "    # 2. 生成sql和答案\n",
    "    content_p_2 = \"\"\"\n",
    "请写sql帮我查询问题。\n",
    "问题：<<question>>\n",
    "已查询获得的事实：<<fact_1>>\n",
    "表结构：<<list>>\n",
    "表之间的关联信息如下：<<foreigns>>\n",
    "表结构中列名可以引用使用,表结构中数据示例只是参考不能引用。\n",
    "我们现在开始查询当前问题，请你分步写出查询sql语句，我把查询结果告诉你，你再告诉我下一步，\n",
    "注意如果我返回的结果为空或者错误影响下一步调用，请重新告诉我sql语句。\n",
    "写sql时，请告诉我<这是第几步，这步做了什么事情>\n",
    "等你全部回答完成，不需要进行下一步调用时，记得提示我：<全部完成，答案如下>,将答案总结以json格式给我，只需要总结当前问题。\n",
    "查询技巧:sql查询年度时优先使用year()函数。sql查询语句不需要注释，不然会报错。sql中日期条件格式应参考这样date(TradingDay) = 'YYYY-MM-DD'。尽量利用表格中已有的字段。\n",
    "\"\"\"\n",
    "    content_p_2 = content_p_2.replace('<question>', question)\\\n",
    "        .replace('<list>', str(LL) + table_intro(LL))\\\n",
    "        .replace('<foreigns>', str(foreigns_choice))\\\n",
    "        .replace('<fact_1>', str((res, tables)))\n",
    "    if concept_list:\n",
    "        content_p_2 = content_p_2 + \"\\n行业提示：\" + str(concept_list)\n",
    "\n",
    "    messages_sql = []\n",
    "    messages_sql.append({\"role\": \"system\", \"content\": content_p_2})  \n",
    "    messages_sql.append({\"role\": \"user\", \"content\": f\"下面开始解决问题：{question}\"})\n",
    "    messages_sql.append({\"role\": \"user\", \"content\": ref.to_string()})  \n",
    "    ###开始对话  \n",
    "    last_answer = run_conversation_until_complete(messages_sql, max_rounds=9, dialog_id = question_id, \n",
    "                                                o_q = question, \n",
    "                                                database_L_zh = database_L_zh,\n",
    "                                                LL = LL +  [i for i in table_maps if i.get('数据表名') in str(tables)])\n",
    "        \n",
    "    return str(last_answer)\n",
    "\n",
    "def find_error_col(text, LL):\n",
    "    \"\"\"\n",
    "     处理sql中的Unknown column错误\n",
    "    \"\"\"\n",
    "    # 查找 \"Unknown column '\" 和 \"' in\"之间的字符串\n",
    "    match = re.search(r\"Unknown column '([^']*)' in\", text)\n",
    "    col_name = match.group(1)\n",
    "    if \".\" in col_name:\n",
    "        col_name = col_name.split(\".\")[-1]\n",
    "    right_table_name = []\n",
    "    for table in LL:\n",
    "        table_shema = table['数据表结构']\n",
    "        for column in table_shema:\n",
    "            if column['列名'] == col_name:\n",
    "                right_table_name.append(table['数据表名'])\n",
    "                break\n",
    "    if len(right_table_name) == 0:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return f\"{col_name} 在 {str(right_table_name)} 表中\"\n",
    "\n",
    "def run_conversation_until_complete(messages, dialog_id, o_q, LL, database_L_zh, max_rounds=6):\n",
    "    \"\"\"\n",
    "    Test function to run a conversation loop until the assistant indicates completion.\n",
    "    \"\"\"\n",
    "    def summarize(messages):\n",
    "        \"\"\"\n",
    "        总结对话内容，生成最终答案\n",
    "        \"\"\"\n",
    "        messages_a = [{\"role\": \"user\", \"content\": f\"根据对话：{str(messages)}，回答问题<{o_q}>，如果答案涉及百分比，加上'%'。只输出答案，不要回答其他内容\"}]\n",
    "        response = async_llm_chain_call(messages_a, MODEL_sql, sampling_count=1)\n",
    "        last_response = response.choices[0].message.content\n",
    "        return last_response\n",
    "    \n",
    "    last_response = None  # 用于存储最后一次对话的响应\n",
    "    round_count = 0  # 对话轮数计数器\n",
    "    # 1. 生成第一次回复\n",
    "    response = async_llm_chain_call(messages, MODEL_sql, sampling_count=1)\n",
    "    pre_sql = \"\"\n",
    "    while True:\n",
    "        # 2. 通过不断对话修改sql，直到LLM回复\"完成\"\n",
    "        del messages[-1]\n",
    "        question = response.choices[0].message.content\n",
    "        # 2.1 根据LLM的回复从关键例子中筛选出与问题相关的例子\n",
    "        ref = Example(question=question, database_L_zh = database_L_zh)\n",
    "        # 2.2 筛选出LLM回复中的sql，并执行sql，得到结果\n",
    "        select_result, intro_str, sql = to_select(question)\n",
    "        if round_count >= max_rounds:\n",
    "            # 如果对话轮数超过最大值，则总结对话内容，生成最终答案\n",
    "            messages.append({\"role\": \"assistant\", \"content\": question})\n",
    "            messages.append({\"role\": \"user\", \"content\": str(select_result)})\n",
    "            last_response = summarize(messages)  # 存储最后一次响应  \n",
    "            break  # 如果对话轮数超过最大值，则退出循环\n",
    "        # 2.3 处理LLM回复的sql，如果有错误，加入错误信息\n",
    "        messages.append({\"role\": \"assistant\", \"content\": question})\n",
    "        if \"Unknown column\" in select_result:\n",
    "            col_position = find_error_col(select_result, LL)\n",
    "            messages.append({\"role\": \"user\", \"content\": col_position})\n",
    "        if pre_sql != sql:\n",
    "            pre_sql = sql\n",
    "            messages.append({\"role\": \"user\", \"content\": str(select_result) + intro_str})\n",
    "        else:\n",
    "            # 如果检测到回答相同，则停止循环\n",
    "            last_response = summarize(messages)  # 存储最后一次响应  \n",
    "            break  \n",
    "        \n",
    "        # 2.4 在对话中加入筛选出的与问题相关的例子\n",
    "        messages.append({\"role\": \"user\", \"content\": ref.to_string()})\n",
    "        # 2.5 根据追加的信息，调用LLM生成新的回复\n",
    "        response = async_llm_chain_call(messages, MODEL_sql, sampling_count=1)\n",
    "\n",
    "        last_response = response.choices[0].message.content  # 存储最后一次响应       \n",
    "        if \"全部完成\" in response.choices[0].message.content:\n",
    "            del messages[-1]\n",
    "            messages.append({\"role\": \"assistant\", \"content\": last_response})\n",
    "            last_response = summarize(messages)\n",
    "            break\n",
    "        round_count += 1\n",
    "    os.makedirs(\"dialog\",exist_ok=True)\n",
    "    with open(f\"dialog/{dialog_id}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(messages, f, ensure_ascii=False, indent=4)\n",
    "    parsed_data = find_json(last_response)\n",
    "    final_string = process_dict(parsed_data)\n",
    "    return final_string  # 返回最后一次对话的内容\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 定义获取问题答案的函数"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from collections import Counter\n",
    "import requests\n",
    "import pickle\n",
    "\n",
    "def get_answer(question, question_id, database_L_zh):\n",
    "    \"\"\"\n",
    "    Attempt to answer the given question by interacting with the \n",
    "    conversation model. If an error occurs, return a default error message.\n",
    "    \n",
    "    Parameters:\n",
    "        question (str): The question that needs an answer.\n",
    "        \n",
    "    Returns:\n",
    "        str: The answer string or an error message if an exception occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Attempting to answer the question: {question}\")\n",
    "        # 写入log文件\n",
    "        with open(\"log.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"Attempting to answer the question: {question}\\n\")\n",
    "        last_answer = run_conversation(question, question_id, database_L_zh)\n",
    "        return last_answer\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while executing get_answer: {e}\")\n",
    "        # 写入log文件\n",
    "        with open(\"log.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"Error occurred while executing get_answer: {e}\\n\")\n",
    "        return \"An error occurred while retrieving the answer.\"\n",
    "    \n",
    "def question_rew(context_text, original_question):\n",
    "    \"\"\"\n",
    "    Rewrite the given question to be clearer and more specific based on the provided context,\n",
    "    without altering the original meaning or omitting any information.\n",
    "    \n",
    "    Parameters:\n",
    "        context_text (str): The context text that the question is based on.\n",
    "        original_question (str): The question to be rewritten.\n",
    "        \n",
    "    Returns:\n",
    "        str: The rewritten question.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        \"请将多回合对话中的用户问题重新表述，使重写的问题可以充分表达用户的信息需求，而不需要上下文。\"\n",
    "        \"要求不改变原意，不要遗漏信息，要包含内容中与问题有关的重要信息（比如代号、公司、股票、职位等），特别是时间。\\n\"\n",
    "        \"我将给你举个多回合对话的例子，每个回合都包含一个问题和重写。重写部分使用json格式，其中解释了为什么要这样重写：\\n\"\n",
    "        \"Example : 之前的对话: '问题：最新更新的2021年度报告中，机构持有无限售流通A股数量合计最多的公司简称是？  回答：公司简称 帝尔激光',\"\n",
    "        \"帮我重写这个问题'在这份报告中，该公司机构持有无限售流通A股比例合计是多少，保留2位小数？' \\n\"\n",
    "        \"\"\"assistant:```json\n",
    "        {\"原因\": \"根据之前的问答，这份报告是指 最新更新的2021年度报告，该公司机构是指 帝尔激光 。所以在用户问题中替换这2个意义不明确的词语，并保留用户的信息需求，即最新更新的2021年度报告中,公司简称 帝尔激光 持有无限售流通A股比例合计是多少，保留2位小数？\",\n",
    "         \"重写\": \"最新更新的2021年度报告中,公司简称 帝尔激光 持有无限售流通A股比例合计是多少，保留2位小数？\"}\n",
    "         ```\\n\"\"\"\n",
    "         \"现在，开始你的任务:\\n\"\n",
    "        f\"之前的对话: '{context_text}',帮我重写这个问题'{original_question}' \\n assistant:\"\n",
    "    )\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = async_llm_chain_call(messages, MODEL_sql, sampling_count=1)\n",
    "    answer = response.choices[0].message.content\n",
    "    try:\n",
    "        rewrite = find_json(answer)[\"重写\"]\n",
    "        return rewrite\n",
    "    except:\n",
    "        prompt = f\"下面的内容是之前的问答'{context_text}'，之前的问答只能作为参考，不一定正确。现在要回答：'{original_question}' \"\n",
    "        return prompt\n",
    "    # prompt = f\"下面的内容是之前的问答'{context_text}'，之前的问答只能作为参考，不一定正确。现在要回答：'{original_question}' \"\n",
    "    # return prompt\n",
    "\n",
    "\n",
    "def main_answer(q_json_list, start_index=0, end_index=None):\n",
    "    \"\"\"\n",
    "    Process a portion of a list of JSON objects, each containing a 'tid' and 'team' \n",
    "    where 'team' is a list of questions.\n",
    "    \n",
    "    For each JSON object in the specified range:\n",
    "      1. Extract all questions from 'team'.\n",
    "      2. If no previous Q&A history, use the question directly. Otherwise, \n",
    "         rewrite the question based on all previously answered content.\n",
    "      3. Get the answer using get_answer and store it.\n",
    "      4. Update the original structure with the answers.\n",
    "    \n",
    "    Parameters:\n",
    "        q_json_list (list): List of data objects, each containing keys 'tid' and 'team'.\n",
    "        start_index (int): The starting index of the list subset to process.\n",
    "        end_index (int): The ending index (non-inclusive) of the list subset. \n",
    "                         If None, process until the end of q_json_list.\n",
    "                         \n",
    "    Returns:\n",
    "        list: A list of processed dictionaries with updated answers.\n",
    "    \"\"\"\n",
    "    if end_index is None or end_index > len(q_json_list):\n",
    "        end_index = len(q_json_list)\n",
    "    os.makedirs(\"result\", exist_ok=True)\n",
    "    # 获取目录下的文件名\n",
    "    file_list = os.listdir(\"result\")\n",
    "    data_list_result = []\n",
    "    for i in tqdm(range(start_index, end_index), desc=\"Processing JSON data in range\"):\n",
    "        item = q_json_list[i]\n",
    "        # if item['tid'] != \"tttt----4\":\n",
    "        #     continue\n",
    "        if item['tid']+\".pkl\" in file_list:\n",
    "            tid = item['tid']\n",
    "            with open(f\"result/{tid}.pkl\", \"rb\") as file:\n",
    "                updated_data = pickle.load(file)\n",
    "            data_list_result.append(updated_data)\n",
    "            continue\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Extract questions\n",
    "        questions_list = [(member[\"id\"], member[\"question\"]) for member in item[\"team\"]]\n",
    "        answers_dict = {}\n",
    "        all_previous = ''\n",
    "\n",
    "        # Iterate over all questions in the current item\n",
    "        for question_id, question_text in questions_list:\n",
    "            if all_previous == '':\n",
    "                rewritten_question = question_text\n",
    "            else:\n",
    "                rewritten_question = question_rew(all_previous, question_text)\n",
    "\n",
    "            answer = get_answer(rewritten_question, question_id, database_L_zh)\n",
    "            print(f'----------answer:{answer}')\n",
    "            # 写入log文件\n",
    "            with open('log.txt', 'a', encoding='utf-8') as f:\n",
    "                f.write(f'----------answer:{answer}\\n')\n",
    "            answers_dict[question_id] = answer\n",
    "            all_previous += \"问题：\" + question_text + \"回答：\" + answer + \"\\n\"\n",
    "\n",
    "        # Update original item with answers\n",
    "        for member in item[\"team\"]:\n",
    "            member[\"answer\"] = answers_dict.get(member[\"id\"], \"无答案\")\n",
    "\n",
    "        updated_data = {\"tid\": item[\"tid\"], \"team\": item[\"team\"]}\n",
    "        tid = item[\"tid\"]\n",
    "        with open(f\"result/{tid}.pkl\", \"wb\") as file:\n",
    "            pickle.dump(updated_data, file)\n",
    "\n",
    "        data_list_result.append(updated_data)\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Completed processing JSON index {i} in {elapsed_time:.2f} seconds\")\n",
    "        # 写入log文件\n",
    "        with open('log.txt', 'a', encoding='utf-8') as f:\n",
    "            f.write(f\"Completed processing JSON index {i} in {elapsed_time:.2f} seconds\\n\")\n",
    "        \n",
    "    return data_list_result\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load input data\n",
    "with open(question_data_path, 'r', encoding='utf-8') as file:\n",
    "    q_json_list = json.load(file)\n",
    "\n",
    "# Users can specify a range to process the corresponding subset of data\n",
    "# For example, from index 0 to 100 (excluding 100), processing the first 100 JSON entries\n",
    "start_idx = 0\n",
    "end_idx = 101  # Specify processing data in the range 0-101\n",
    "\n",
    "results = main_answer(q_json_list, start_index=start_idx, end_index=end_idx)\n",
    "\n",
    "# Write the processing results to a file\n",
    "with open('result.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(results, json_file, ensure_ascii=False, indent=4)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatMed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
